# ğŸ›¡ï¸ MCP Directory â€“ Windsurf IDE Rules

## ğŸ§± Project Architecture

- This is a **Model Context Protocol (MCP) directory** app using:
  - Supabase MCP (auth, DB, edge functions)
  - Vercel CLI (frontend hosting, edge deploy)
  - Firecrawl MCP (external crawling & data ingestion)

- The app consists of 4 main layers:
  1. **Frontend (React + Tailwind + Shadcn UI)**
  2. **Edge Functions (Supabase)**
  3. **Database Schema (Postgres)**
  4. **MCP Agents + Crawl Logic**

---

## ğŸ“ Naming Conventions

- File names: kebab-case (e.g., `server-card.tsx`, `cli-generator-tool.md`)
- Function names: camelCase for JavaScript, snake_case for SQL
- API endpoints:
  - `/servers/search`
  - `/servers/:id`
  - `/servers/health`
  - `/cli/generate`
  - `/crawl/start`

---

## ğŸ§  Prompt Strategy

- Use **modular prompts** for each feature or file
- Follow the 3-part format:
  1. ğŸ¯ **Goal** â€“ high-level intent
  2. ğŸ§  **Task Breakdown** â€“ detailed implementation steps
  3. âœ… **Deliverables** â€“ what the output must contain

---

## ğŸ”„ Function Standards

- Edge functions must:
  - Be RESTful and stateless
  - Validate input parameters
  - Return typed JSON
  - Use Supabase client and secure env vars
  - Enforce RLS via policy (anonymous read allowed for public endpoints)

- All GETs must support:
  - Pagination (limit, offset) if data > 50
  - Caching headers where safe

---

## ğŸ–¥ï¸ UI Standards

- Use `Shadcn UI` components and `TailwindCSS`
- Ensure:
  - Mobile responsiveness
  - Accessible components (WCAG 2.1)
  - Visual cues for server health and install method
  - Keyboard navigation support

---

## ğŸ—‚ï¸ Folder Structure
/components
	â€¢	ServerCard.tsx
	â€¢	CLIGenerator.tsx

/pages
	â€¢	Discover.tsx
	â€¢	ServerDetail.tsx

/functions
	â€¢	crawl-start.ts
	â€¢	servers-search.ts
	â€¢	servers-id.ts
	â€¢	servers-health.ts
	â€¢	cli-generate.ts

/prompts
	â€¢	*.md (prompt definition files)

/schemas
	â€¢	servers.sql
	â€¢	server_status.sql

---

## ğŸ” Supabase RLS Rules

- Public anonymous users can:
  - Read from `servers`, `server_status`, `compatibility`, `metrics`
- Only internal edge functions can:
  - Insert/update into `servers`, `server_status`, `metrics`
  - Write via service role or elevated token

---

## ğŸ“¬ API Error Handling

- Always return structured errors:
```json
{
  "error": true,
  "message": "Missing server ID",
  "code": 400
}
```
- Use HTTP status codes:
	â€¢	200 OK  
	â€¢	400 Bad Request  
	â€¢	404 Not Found  
	â€¢	500 Internal Error

---

## âœ… Deployment & Build Rules
- Frontend is deployed to Vercel from `/frontend`
- Use `vercel.json` to define routes and function settings
- Edge functions are bundled using Supabase MCP and triggered via Vercel functions or middleware
- Supabase keys and GitHub tokens are stored securely in Vercel project environment variables


---

## ğŸ§ª Testing Requirements
- Every page/component must include:
	â€¢	Loading state  
	â€¢	Empty state  
	â€¢	Error state  
- Edge functions must:
	â€¢	Be testable via Postman or CLI script  
	â€¢	Return mock-friendly outputs  

---

## ğŸŒ Internationalization
- Use English as default UI language
- Plan for i18n-ready components with message keys
- Add language field to server records when relevant

---

## ğŸ§  AI Agents (Optional)
- MCP-aware LLMs like Claude/DeepSeek may be added for:
	â€¢	Install walkthroughs  
	â€¢	Health diagnostics  
	â€¢	Compatibility checks  

---

## ğŸ§¾ Issue Resolution Workflow

1. **Review First**:  
   - Before implementing any fix, always carefully review all **code** and **log files**.  
   - Think through the problem step by step.

2. **Check Linear MCP**:  
   - Open Linear and **search for existing tasks** related to the issue.  
   - If no task exists, **create a new one** with a clear and descriptive title.

3. **Document the Issue**:  
   - In the Linear task, document:
     - A detailed description of the issue  
     - Relevant logs or code snippets  
     - Your **step-by-step plan** to resolve the issue

4. **Implement & Test**:  
   - Execute the fix and run all relevant tests (Postman, CLI, browser).  
   - Ensure the fix passes and covers loading, empty, and error states where applicable.

5. **Close the Loop**:  
   - Once testing is complete, update the Linear task:  
     - Set status to `"Complete"` or `"Done"`  
     - Add a summary of what was implemented and how it resolved the issue

---

## âœ… Always Do
- Break large features into smaller prompts
- Use code comments in all functions
- Define types/interfaces in a separate types/ folder
- Link prompts to actual output files clearly

## ğŸš« Never Do
- Mix inline type definitions
- Hardcode server IDs or URLs
- Block anonymous reads on public endpoints
- Rely on client-side only for install command logic

---

- Do not give me code unless I explicitly ask for it.
- Guide me in problem-solving instead of providing direct answers.
- When I ask about programming concepts (e.g., "What is a hook?"), give me a direct and clear explanation.
- Break problems into smaller, manageable steps and help me think through them.
- Ask leading questions and provide hints instead of just telling me the answer.
- Encourage me to debug independently before offering suggestions.
- Refer me to relevant documentation instead of providing solutions.
- Encourage modular thinkingâ€”breaking problems into reusable components.
- Remind me to reflect on what I learned after solving an issue.
- If I explicitly ask for code (e.g., "Give me the code"), then you can provide it.
- Encourage me to read and understand error messages instead of just fixing the issue for me.
- Help me identify patterns in my mistakes so I can improve my debugging skills.
- Suggest different approaches instead of leading me to one specific solution.
- Guide me toward using console.log(), browser dev tools, and other debugging techniques.
- Help me understand how to search effectively (e.g., Googling error messages or checking documentation)

ğŸ¯ **Goal**  
Implement a fix for the identified issue and verify it's resolved.

ğŸ§  **Task Breakdown**
1. Apply the fix in the correct layer (DB, edge function, or UI).
2. Write unit/integration tests if applicable.
3. Validate it via CLI or Postman (for edge functions) or browser for UI.

âœ… **Deliverables**
- Committed code with comments
- Updated test coverage
- Confirmation that issue is no longer reproducible

ğŸ¯ **Goal**  
Ensure every technical issue is documented and tracked before implementation.

ğŸ§  **Task Breakdown**
1. Review the logs and source code to understand the issue.
2. Open Linear MCP and search for existing tasks.
3. If not found, create a new task and document:
   - Logs, screenshots, error codes
   - The suspected cause
   - Your hypothesis for resolving it

âœ… **Deliverables**
- Linear task with a complete description
- Initial root cause analysis

ğŸ¯ **Goal**  
Close the loop in Linear MCP once the fix has been tested.

ğŸ§  **Task Breakdown**
1. Update the task status to "Complete" or "Done"
2. Add a comment with:
   - What was implemented
   - How it was tested
   - Any side effects or dependencies updated

âœ… **Deliverables**
- Task marked done
- Final implementation summary added to Linear
